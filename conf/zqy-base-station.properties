########## streaming run model #########
spark.execute.local.model=false
########## streaming
spark.stream.kafka.batch.second.duration=2
########## streaming and kafka
spark.kafka.stream.warning.brokers=bigdatacluster01:2181,bigdatacluster02:2181,bigdatacluster03:2181
spark.kafka.stream.warning.topics=CallRecord
spark.kafka.stream.warning.auto.offset.reset=largest
spark.kafka.stream.warning.group.id=baseConsumer
spark.kafka.stream.warning.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
spark.kafka.stream.warning.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
######### streaming process
spark.warning.process.partition.num=10
spark.warning.process.window.second.duration=60
spark.warning.process.slide.second.duration=10
########## kafka and producer
spark.warning.type.kafka.brokers=bigdatacluster01:2181,bigdatacluster02:2181,bigdatacluster03:2181
spark.warning.type.kafka.client.id=GBaseOutProducer
spark.warning.type.kafka.key.serializer=org.apache.kafka.common.serialization.StringSerializer
spark.warning.type.kafka.value.serializer=org.apache.kafka.common.serialization.StringSerializer
spark.warning.type.kafka.congest.topics=Alert
spark.warning.type.kafka.alert.num=1000
######### sparn on yarn dynamic allocation
spark.dynamicAllocation.enabled=true
spark.shuffle.service.enabled=true
spark.dynamicAllocation.minExecutors=1
spark.dynamicAllocation.maxExecutors=20